{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "presentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zoldello/pytorch-presentation-nov-2018/blob/master/presentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xmqkeKIXiuKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## Philip Adenekan \n",
        "## Basic Deep Neural Network with Pytorch\n",
        "## Cherry Lab Dev Meeting\n",
        "## Cherry Lab\n",
        "## November, 2018\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0-uwYwMr96AJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# IGNORE. COLLAB INITIALIZATION CODE \n",
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtLrLieojOGJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Overview \n",
        "- What is Pytorch?\n",
        "- Levels of Abstraction\n",
        "    - Tensors\n",
        "    - Variable\n",
        "    - Module\n",
        "- MNIST dataset\n",
        "- Artificial Neural Network\n",
        "- References\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5YN2gw2gkWwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Pytorch\n",
        "Itâ€™s a **Python-based scientific computing package** targeted at two sets of audiences:\n",
        "1.   A replacement for NumPy, with added GPU support \n",
        "2.   A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "**Presentation based on v0.41; v1 is in preview.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hH43_SSlcWQN"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# More on Pytorch\n",
        "- Facebook's Python-port of Torch (Torch written in Lua) \n",
        "\n",
        "- Users: Facebook, Uber,  Tesla, some labs in Stanford and many others in industry and academia\n",
        "\n",
        "- Andrej Karpathy quote- \"*... using Pytorch... I've never felt better. I have more energy. My skin is clearer. My eye sight  has improved*\" [4]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "HWcdc6ESHPiS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Three Levels of Abstration\n",
        "- **Tensor**: ndarray that runs can on GPU\n",
        "- **Variable**: Store data and gradient\n",
        "- **Module**: Neural Network functionality like stores weights \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0xqekJCPj0DJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "#  Tensor\n",
        "\n",
        "- What is a Tensor\n",
        "    - Simple Definition: **An array/list of n rows and m column**\n",
        "    - Proper Definition:  A tensor is an arbitrarily complex geometric object that maps in a (multi-)linear manner geometric vectors, scalars, and other tensors to a resulting tensor. \n",
        "    \n",
        "    **    Lets stick with the simple defintion**\n",
        "\n",
        "- Nomenclature of a group of number in Computer Science vs Mathematics:\n",
        "<table>\n",
        "    <th>\n",
        "        <td></td>\n",
        "        <td>**Number**<td>\n",
        "         <td>**1 X n Numbers **<td>\n",
        "                <td>**n X m Numbers**<td>\n",
        "    </th>\n",
        "    <tr>\n",
        "         <td>Computer Scientist<td>\n",
        "         <td>int<td>\n",
        "                <td>array<td>\n",
        "            <td>nd-array<td>\n",
        "    <tr>\n",
        "            <tr>\n",
        "         <td>Mathematicians<td>\n",
        "         <td>scalar<td>\n",
        "                <td>vector<td>\n",
        "            <td><b>tensor</b><td>\n",
        "    <tr>\n",
        "   </table>\n",
        "\n",
        "- **Tensor** is heavily used in Pytorch.\n",
        "- Tensor  used to model scalar and vectors (okay in Machine Learning)\n",
        "                \n",
        "- Slew of operations possible- Transport, arthmetic, etc\n",
        "                \n",
        "- Tensors can  be converted to Numpy array and vice versa\n",
        "\n",
        "               \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YX1gyE7-ik-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch # pytorch library\n",
        "from torch import autograd \n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Skip in presentation\n",
        "# run GPU iff available\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MidL7qevp7RS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Pytorch Tensors\n",
        "\n",
        "- Creating a Tensor\n",
        "\n",
        "\n",
        "```\n",
        "x = torch.tensor([1,2]) # 1-D tensor, vector\n",
        "x = torch.tensor([[1,2], [3,4]]) # 2-D tensor, matrix\n",
        " \n",
        "\n",
        "```\n",
        "\n",
        "Many other means to create a tensor:\n",
        "- x = torch.rand(1,2)\n",
        "- x =  torch.zeros(1,2)\n",
        "- x = torch.ones(1,2)\n",
        "- x = torch.Tensor(1,2)\n",
        "- x = torch.FloatTensor([1,2,3])\n",
        "- x = torch.DoubleTensor([1,2,3])\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "d6sphTczs6Mq",
        "colab_type": "code",
        "outputId": "5d6b96a4-a173-43a4-e26e-1b3fa7b40d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "# building a tensor\n",
        "x = torch.tensor([[1.0,2.], [3.,4.]])\n",
        "print(f'Tensor: {x}')\n",
        "print(f'Type: {type(x)}')\n",
        "print(f'DType: {x.dtype}')\n",
        "print(f'Mean: {x.mean()}')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor: tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "Type: <class 'torch.Tensor'>\n",
            "DType: torch.float32\n",
            "Mean: 2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZIid1hitm1T",
        "colab_type": "code",
        "outputId": "a39c6cd6-9d88-4e7e-bee4-b4baec57df0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# tensor information\n",
        "x = torch.tensor([1,2])\n",
        "print(f'Shape: {x.shape}') # count of rows and columns\n",
        "print(f'Size : {x.size()}') # equivalent to shape\n",
        "print(f'Dimension: {x.dim()}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: torch.Size([2])\n",
            "Size : torch.Size([2])\n",
            "Dimension: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YXXmDAiaj0VM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Y_4LMHSp05Mi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Variables \n",
        "- ### Variable deprecated in v1 pre-release, just autograd needed \n",
        "- Tensor wrapper for storing gradient(stores operations performed on said tensor)\n",
        "- Three componenets\n",
        "    - data; Retrieve tensor\n",
        "    - grad: gradient\n",
        "    - grad_fn: function object for creating variable\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JBgsAs-4rrL5",
        "colab_type": "code",
        "outputId": "c1b55025-4f72-468a-8dd4-2ffcf76a1729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# creating a Variable\n",
        "y = Variable(torch.tensor([1.0,2.0], requires_grad=True)) # tensor must be a float\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxOeu3Ym_d4i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Module\n",
        "- Contains methods for building various types of Neural Networks\n",
        "    -  ### Multi-layer perceptron\n",
        "    - Convolutional Neural Network\n",
        "    - Recurrent Neural Networks\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-8N5JopoGysu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "#MNIST Dataset\n",
        "- Collection of handwritten number from 0 - 9 [12], [13]\n",
        "- Stored in 28 X 28 array of grayscale color\n",
        "- Used as a base test in Machine Learning (akin to  ** *Drosophila melanogaster* of machine Learning **)\n",
        "- Sample: \n",
        "![alt text](http://ml4a.github.io/images/figures/mnist-input.png)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "07_KFslOO3-p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Artifical Neural Network \n",
        "- Biologically inspired collection of nodes \n",
        "\n",
        "-  Model non-linear functions\n",
        "\n",
        "- Needs training, test and validation data sets\n",
        "\n",
        "- Has three layers\n",
        "    - Input \n",
        "    - Hidden \n",
        "    - Output\n",
        "\n",
        "- Illustration: \n",
        "\n",
        "![alt text](https://i.stack.imgur.com/gzrsx.png)\n",
        "\n",
        "\n",
        "** Y = ReLu( (x1 * w1 + x2 * w2 + x3 * w3)  ) **\n",
        "\n",
        "\n",
        "Ouput as a Tensor:\n",
        "** y = X * W **\n",
        "\n",
        "Fig 1: A Simple Neural Network [12]\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sWIskR_6B7Yv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- Activation function\n",
        "    - Introduces non-linearity\n",
        "    - Determines if a node fires or not\n",
        "    - Examples: ReLU, Sigmoid, Tanh\n",
        "    - ReLU: 0 if value is <=0, else return value\n",
        "\n",
        "- Bias: Optional values added to a node, can ensure a node weighted sum is not zero\n",
        "\n",
        "\n",
        "![Neural Network](https://cdn-images-1.medium.com/max/1200/1*0NKtEk20-qnaLkwOa8DlnA.png)\n",
        "Fig 2. More detailed image of a Neural Network [5]\n",
        "\n",
        "- **Input, weights and outputs of nodes can be treated as Tensor**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7De8L6UZdjFI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Learning in Neural Network\n",
        "\n",
        "- Find weights that make error very low\n",
        "\n",
        "- Modeled as a convex optimization problem (see [11] for details)\n",
        " \n",
        "\n",
        "![Neural Network error vs weight](http://www.cs.cornell.edu/boom/2004sp/projectarch/appofneuralnetworkcrystallography/images/NeuralNetworkErrorCurve.jpg)\n",
        "\n",
        "\n",
        "- Learning is about converging/moving towards to a **global minimum**\n",
        "\n",
        "- Learning rate is speed at which this takes place\n",
        "    - Too low and it takes too long to converge\n",
        "    - Too high and you get overshooting\n",
        "\n",
        "- Note: Given there are multiple weights, the graph above is overly simplied"
      ]
    },
    {
      "metadata": {
        "id": "vJksD4lgRe-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Deep Neural Networks\n",
        "\n",
        "- Large number of nodes and multi-layed\n",
        "\n",
        "- Better at modeling complex equation than shallow Neural Network\n",
        "\n",
        "- Exploded-popularity due to great results\n",
        "    - In some cases, better at image classification than humans [6]\n",
        "    - Defeated best go-players [7]\n",
        "    - Gaining popularity in biomedical imaging [8]\n",
        "    - Widely used in autonomous vehicles [9]\n",
        "   \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XkkFextIVIIy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Deep Neural Networks Not a Magic Bullet\n",
        "- Need lots of data (Thousands of training-samples is nice)\n",
        "\n",
        "- Even with GPU, can take a long time to train\n",
        "\n",
        "- Overkill for small-class problems like linear problems\n",
        "\n",
        "- A black box (Interpretation an active research area)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EBpANZ4lW7oC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Pytorch-Neural Network Setup\n",
        "- Layers\n",
        "-  Forward Propagation\n",
        "- Training\n",
        "- Validation\n",
        "- Quantification with test data (beyond scope)\n",
        "\n",
        "- This demo will be based on work in [10]\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FDsFN8LP5FP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # deep learning class\n",
        "import torchvision.datasets as dsets # MNIST data (repository of handwriting samples for image analysis [28 X 28 matrix])\n",
        "import torchvision.transforms as transforms # auxillary, used for processing data to tensor\n",
        "from torch.autograd import Variable # autograd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOulaVlA6Yjf",
        "colab_type": "code",
        "outputId": "f5a902c5-4ac4-4052-fc4d-f60cbb57afc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "cell_type": "code",
      "source": [
        "# accessing MNIST data (pytorch comes with a sample along with Iris [flowers])\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                           train=True,\n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rhZWJNKly29N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters- Things you can adjust to better train network \n",
        "batch_size = 100       # Size of input data used for one iteration\n",
        "input_size = 784       # The image size = 28 x 28 = 784\n",
        "hidden_size = 500      # Number of nodes in the hidden layer\n",
        "num_classes = 10       # Number of output classes. In this case, from 0 to 9\n",
        "num_epochs = 5         # Number of times entire dataset is trained\n",
        "learning_rate = 0.001  # The speed of convergence\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8f8F5_qa6znn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data loaders\n",
        "# Means of accessing data (like the spoon used to get soup from a pot)\n",
        "# dataset: dataset\n",
        "# batch-size, number of data samples used \n",
        "# shuffle = true, randomly draw batch-size number of data from dataset\n",
        "#\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5N2tTbfwLhx7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What we are building:\n",
        "\n",
        "![alt text](http://adventuresinmachinelearning.com/wp-content/uploads/2017/07/CNTK-Dense-example-architecture.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "zD8My71QXd4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # base class for a deep neural network\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module): # Module, one of the three levels of Pytorch\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # setting up Deep Neural Network\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) # first hidden layer, input=784, output=500\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes) # second hidden layer, input=500, output=10\n",
        "        self.activation_fn = nn.ReLU()\n",
        "        \n",
        "    # forward propagation\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.activation_fn(out) # ReLU activation function on first layer\n",
        "        out = (self.fc2(out)) # ReLU on second hidden layer \n",
        "        return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7LDTkwxaNqs",
        "colab_type": "code",
        "outputId": "9ce54d42-7217-44b5-c075-1646462cb243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "# lets preview the network\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            "  (activation_fn): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yDHQmWdl-vWO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function used for determining error\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate) # way of updating weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVpbRzEJ_Hda",
        "colab_type": "code",
        "outputId": "3c1a69f3-c9fc-4a59-b388-e45bc62b2280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        }
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros, calculate gradients for this iterate only\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "              \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "#             _, predicated = torch.max(outputs.data, 1)\n",
        "\n",
        "#             total  += labels.size(0)\n",
        "#             correct += (predicted == labels).sum()\n",
        "#             accuracy = 100 * correct / total\n",
        "        \n",
        "            #TODO: Add accuract\n",
        "            print(f'Epoch: [{epoch+1}/{num_epochs}],   Step: [{i+1}/{len(train_dataset)//batch_size}], Loss: [{loss.data[0]}]')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1/5],   Step: [100/600], Loss: [0.05513649806380272]\n",
            "Epoch: [1/5],   Step: [200/600], Loss: [0.08745250850915909]\n",
            "Epoch: [1/5],   Step: [300/600], Loss: [0.09646078199148178]\n",
            "Epoch: [1/5],   Step: [400/600], Loss: [0.12351468205451965]\n",
            "Epoch: [1/5],   Step: [500/600], Loss: [0.07366239279508591]\n",
            "Epoch: [1/5],   Step: [600/600], Loss: [0.11368696391582489]\n",
            "Epoch: [2/5],   Step: [100/600], Loss: [0.14311593770980835]\n",
            "Epoch: [2/5],   Step: [200/600], Loss: [0.04913290590047836]\n",
            "Epoch: [2/5],   Step: [300/600], Loss: [0.058086782693862915]\n",
            "Epoch: [2/5],   Step: [400/600], Loss: [0.06580042093992233]\n",
            "Epoch: [2/5],   Step: [500/600], Loss: [0.11355315893888474]\n",
            "Epoch: [2/5],   Step: [600/600], Loss: [0.1180448904633522]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3f30bf6b1c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Intialize the hidden weight to all zeros, calculate gradients for this iterate only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Forward pass: compute the output class given a image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Compute the loss: difference between the output class and the pre-given label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                   \u001b[0;31m# Backward pass: compute the weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5427f55082b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ReLU activation function on first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ReLU on second hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vomQ7RvX-rjP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Topics for another day\n",
        "\n",
        "- ## Backpropagation\n",
        "    - Loss function (MSE, CrossEntropy, etc)\n",
        "    - Gradients\n",
        "    - Optimizer (like Adam, Neterov SGD, etc)\n",
        "- Other kinds of network like CNN, RNN\n",
        "- More advanced features of Pytorch\n",
        "- Turning \n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XCfQEth_LMuP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#References\n",
        "\n",
        "\n",
        "1.  Pytorch documentation (stable-v0.41): https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "- Pytorch documentaiotn (preview- v1.0): https://pytorch.org/docs/master/\n",
        "\n",
        "- Variable Deprecation: https://pytorch.org/docs/stable/autograd.html#variable-deprecated\n",
        "\n",
        "-  Andrej Karpathy quote:\n",
        "https://twitter.com/karpathy/status/868178954032513024\n",
        "\n",
        "- Image of Neural Network: https://cdn-images-https://hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491\n",
        "\n",
        "- 6 areas where artificial neural networks outperform humans: https://venturebeat.com/2017/12/08/6-areas-where-artificial-neural-networks-outperform-humans/\n",
        "\n",
        "- AlphaGo: https://en.wikipedia.org/wiki/AlphaGo\n",
        "\n",
        "- Deep Learning Applicatins in Medical Imaging: https://www.techemergence.com/deep-learning-applications-in-medical-imaging/ \n",
        "\n",
        "- How important is deep learning in autonmous driving?- https://www.quora.com/How-important-is-deep-learning-in-autonomous-driving\n",
        "\n",
        "- A Simple Starter Guide to Build a Neural Network:  https://towardsdatascience.com/a-simple-starter-guide-to-build-a-neural-network-3c2cf07b8d7c\n",
        "\n",
        "- Gradient descent, how neural networks learn | Deep learning, chapter 2:  https://www.youtube.com/watch?v=IHZwWFHWa-w&t=1063s\n",
        "\n",
        "- MNIST: http://yann.lecun.com/exdb/mnist/\n",
        "\n",
        "- MNIST Wiki- https://en.wikipedia.org/wiki/MNIST_database"
      ]
    },
    {
      "metadata": {
        "id": "A3bobUmVeqq8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "\n",
        "## Primary Documentation\n",
        "- v0.41. (stable): https://pytorch.org/docs/stable/index.html\n",
        "- v1.02: https://pytorch.org/docs/master/\n",
        "\n",
        "## YouTube\n",
        "\n",
        "- Deep Learning with PyTorch: Building a Simple Neural Network| packtpub.com: https://www.youtube.com/watch?v=VZyTt1FvmfU\n",
        "\n",
        "- Deep Lizard Training in Pytorch: https://www.youtube.com/watch?v=v5cngxo4mIg&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG\n",
        "\n",
        "- 3Blue1Brown (Lot of information about Mathematics relevant to Machine Learning): https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw\n",
        "\n",
        "\n",
        "- Siraj Raval (Produces a lot of videos explain Machine Learning): https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A\n",
        "\n",
        "\n",
        "## Online Conference\n",
        "-PyTorch developer conference part 1: https://www.youtube.com/watch?v=KJAnSyB6mME&t=4593s\n",
        "\n",
        "- PyTorch developer conference part 2: https://www.youtube.com/watch?v=8881p8p3Guk&t=90s\n",
        "\n",
        "- PyTorch developer conference part 3: https://www.youtube.com/watch?v=JVT4XvixNvs\n",
        "\n",
        "\n",
        "\n",
        "## Books\n",
        "- Deep Leaning by GoodFellow et al - http://www.deeplearningbook.org\n",
        "\n",
        "\n",
        "\n",
        "There are a lot of blogs and videos on Machine Learning. "
      ]
    }
  ]
}